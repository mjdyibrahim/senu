{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from typing import Dict, Any\n",
    "\n",
    "# Load the SpaCy model (make sure you have the correct model installed, e.g., 'en_core_web_sm')\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "def extract_entities(text: str) -> Dict[str, Any]:\n",
    "    doc = nlp(text)\n",
    "    entities = {\n",
    "        \"Name\": None,\n",
    "        \"Title\": None,\n",
    "        \"Availability_Per_Week\": None,\n",
    "        \"Involved_Since\": None,\n",
    "        \"Equity_Percent\": None,\n",
    "        \"Salary_Percent\": None,\n",
    "        \"Years_of_Experience\": None,\n",
    "        \"Academic_Degree\": {\n",
    "            \"Undergraduate\": False,\n",
    "            \"Graduate_Degree\": False,\n",
    "            \"Masters\": False,\n",
    "            \"PhD_or_More\": False,\n",
    "        },\n",
    "        \"Startup_Experience\": {\n",
    "            \"Has_Been_Part_of_a_Startup_Team\": False,\n",
    "            \"Has_Been_the_Founder_of_a_Startup\": False,\n",
    "            \"Has_Previous_C_Level_Position\": False,\n",
    "            \"Has_Been_Part_of_a_Successful_Exit\": False,\n",
    "        },\n",
    "        \"Role\": {\n",
    "            \"Marketing\": False,\n",
    "            \"Sales\": False,\n",
    "            \"Product\": False,\n",
    "            \"Creative\": False,\n",
    "            \"Technical\": False,\n",
    "            \"Operation\": False,\n",
    "            \"Other\": None,\n",
    "        },\n",
    "        # Add more fields as needed\n",
    "    }\n",
    "\n",
    "    for ent in doc.ents:\n",
    "        # Example mappings (adjust these based on your specific entity recognition needs)\n",
    "        if ent.label_ == \"PERSON\":\n",
    "            entities[\"Name\"] = ent.text\n",
    "        elif ent.label_ == \"TITLE\":\n",
    "            entities[\"Title\"] = ent.text\n",
    "        # Map other entities accordingly\n",
    "\n",
    "    return entities\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@app.route('/process_data', methods=['POST'])\n",
    "def process_data():\n",
    "    if 'file' not in request.files:\n",
    "        flash('No file part')\n",
    "        return redirect(request.url)\n",
    "\n",
    "    file = request.files['file']\n",
    "\n",
    "    if file and allowed_file(file.filename):\n",
    "        filename = secure_filename(file.filename)\n",
    "        filepath = os.path.join(app.config['UPLOAD_FOLDER'], filename)\n",
    "        file.save(filepath)\n",
    "\n",
    "        # Process the PDF file and extract text\n",
    "        text_data = process_pdf(filepath)\n",
    "\n",
    "        # Extract entities from the text\n",
    "        extracted_entities = extract_entities(text_data)\n",
    "\n",
    "        # Pass the extracted data to your data structure\n",
    "        team_member_data = TeamMember(**extracted_entities)\n",
    "\n",
    "        # Example: Printing extracted data for debugging\n",
    "        print(team_member_data.json())\n",
    "\n",
    "        # Further processing...\n",
    "        return jsonify(team_member_data.dict())\n",
    "\n",
    "    return redirect(request.url)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_llm_and_pdf_responses(llm_response: str, pdf_text: str) -> Dict[str, Any]:\n",
    "    # Extract entities from LLM response\n",
    "    llm_entities = extract_entities(llm_response)\n",
    "\n",
    "    # Extract entities from PDF text\n",
    "    pdf_entities = extract_entities(pdf_text)\n",
    "\n",
    "    # Combine both dictionaries\n",
    "    combined_entities = {**llm_entities, **pdf_entities}\n",
    "\n",
    "    return combined_entities\n",
    "\n",
    "@app.route('/process_data_with_llm', methods=['POST'])\n",
    "def process_data_with_llm():\n",
    "    if 'file' not in request.files or 'llm_response' not in request.form:\n",
    "        flash('No file part or LLM response')\n",
    "        return redirect(request.url)\n",
    "\n",
    "    file = request.files['file']\n",
    "    llm_response = request.form['llm_response']\n",
    "\n",
    "    if file and allowed_file(file.filename):\n",
    "        filename = secure_filename(file.filename)\n",
    "        filepath = os.path.join(app.config['UPLOAD_FOLDER'], filename)\n",
    "        file.save(filepath)\n",
    "\n",
    "        # Process the PDF file and extract text\n",
    "        pdf_text = process_pdf(filepath)\n",
    "\n",
    "        # Combine LLM response with PDF extraction\n",
    "        combined_entities = process_llm_and_pdf_responses(llm_response, pdf_text)\n",
    "\n",
    "        # Pass the combined data to your data structure\n",
    "        team_member_data = TeamMember(**combined_entities)\n",
    "\n",
    "        # Example: Printing extracted data for debugging\n",
    "        print(team_member_data.json())\n",
    "\n",
    "        # Further processing...\n",
    "        return jsonify(team_member_data.dict())\n",
    "\n",
    "    return redirect(request.url)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
